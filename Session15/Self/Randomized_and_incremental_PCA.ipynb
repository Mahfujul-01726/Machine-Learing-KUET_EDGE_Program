{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj_7XoGvu69m",
        "outputId": "a720da3a-33f9-4103-ce99-135eaa08da5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomized PCA Components:\n",
            "[[-0.15336137 -0.60291665  0.43209116  0.24728533  0.60425077]\n",
            " [ 0.65579452 -0.11140889 -0.38625915  0.63497614  0.07162944]]\n",
            "\n",
            "Incremental PCA Components:\n",
            "[[-0.15140083 -0.60178383  0.43601879  0.24785611  0.60281753]\n",
            " [ 0.65660378 -0.11118047 -0.38492501  0.63503451  0.07123399]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA, IncrementalPCA\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "# Generate synthetic data\n",
        "X, _ = make_blobs(n_samples=1000, n_features=5, random_state=42)\n",
        "\n",
        "# Standardizing the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Randomized PCA\n",
        "randomized_pca = PCA(n_components=2, svd_solver='randomized', random_state=42)\n",
        "X_randomized_pca = randomized_pca.fit_transform(X_scaled)\n",
        "\n",
        "print(\"Randomized PCA Components:\")\n",
        "print(randomized_pca.components_)\n",
        "\n",
        "# Incremental PCA (batch size of 100)\n",
        "incremental_pca = IncrementalPCA(n_components=2)\n",
        "for batch in np.array_split(X_scaled, 10):  # Splitting data into 10 batches\n",
        "    incremental_pca.partial_fit(batch)\n",
        "\n",
        "X_incremental_pca = incremental_pca.transform(X_scaled)\n",
        "\n",
        "print(\"\\nIncremental PCA Components:\")\n",
        "print(incremental_pca.components_)\n"
      ]
    }
  ]
}